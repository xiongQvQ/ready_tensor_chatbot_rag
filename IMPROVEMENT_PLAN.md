# ReadyTensor é¡¹ç›®æ”¹è¿›æ–¹æ¡ˆ

## ğŸ“‹ åé¦ˆæ€»ç»“

### Publication åé¦ˆ
1. âŒ ç¼ºå°‘è¯¦ç»†çš„å®‰è£…å’Œä½¿ç”¨è¯´æ˜
2. âŒ ç¼ºå°‘å®é™…åº”ç”¨åœºæ™¯å’Œå®é™…æ„ä¹‰è¯´æ˜
3. âŒ ç¼ºå°‘guardrailsï¼ˆæŠ¤æ ï¼‰ã€å®‰å…¨æªæ–½çš„è¯´æ˜
4. âŒ ç¼ºå°‘è®°å¿†æœºåˆ¶ï¼ˆmemory mechanismsï¼‰
5. âŒ ç¼ºå°‘æ£€ç´¢æ€§èƒ½è¯„ä¼°ï¼ˆretrieval performance evaluationï¼‰
6. âŒ æ ‡é¢˜ä¸å¤Ÿå…·ä½“ï¼Œéœ€è¦é¡¹ç›®ç›¸å…³çš„æ ‡é¢˜
7. âŒ éœ€è¦æ›´å¤šé¡¹ç›®ç›¸å…³æ ‡ç­¾
8. âŒ æ•´ä½“publicationçœ‹èµ·æ¥ä¸å®Œæ•´

### Repository åé¦ˆ
1. âŒ ç¼ºå°‘Licenseæ–‡ä»¶
2. âŒ éœ€è¦å®šä¹‰æ–‡æ¡£é¢†åŸŸï¼ˆdocument domainï¼‰
3. âŒ éœ€è¦ç¡®ä¿çŸ¥è¯†åº“é›†æˆè¯´æ˜
4. âŒ éœ€è¦åŠ å…¥æ£€ç´¢æ€§èƒ½æµ‹é‡å’Œè¯„ä¼°

---

## ğŸ¯ æ”¹è¿›æ–¹æ¡ˆæ¦‚è§ˆ

### Phase 1: ç´§æ€¥å¿…éœ€ï¼ˆ1-2å¤©ï¼‰âš¡ P0
**ç›®æ ‡ï¼šæ»¡è¶³åŸºæœ¬åˆè§„è¦æ±‚**

#### 1. æ·»åŠ  LICENSE æ–‡ä»¶
- [ ] åˆ›å»º MIT License æ–‡ä»¶åœ¨æ ¹ç›®å½•
- [ ] åœ¨ README.md ä¸­æ·»åŠ  License å¾½ç« å’Œè¯´æ˜
- **å·¥ä½œé‡ï¼š30åˆ†é’Ÿ**

```markdown
# åœ¨ README ä¸­æ·»åŠ 
![License](https://img.shields.io/badge/license-MIT-green.svg)

## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
```

#### 2. æ”¹è¿›é¡¹ç›®æ ‡é¢˜
- [ ] å°†æ ‡é¢˜ä» "Research Assistant Chatbot" æ”¹ä¸ºæ›´å…·ä½“çš„åç§°
- **å»ºè®®æ ‡é¢˜ï¼š**
  - "RAG-Powered ML Research Knowledge Assistant"
  - "Intelligent Research Document Q&A: LangChain RAG System"
  - "Smart Research Assistant: Semantic Search Chatbot for ML Literature"
- **å·¥ä½œé‡ï¼š30åˆ†é’Ÿ**

#### 3. æ·»åŠ é¡¹ç›®æ ‡ç­¾
- [ ] åœ¨ ReadyTensor publication ä¸­æ·»åŠ  10-15 ä¸ªæ ‡ç­¾
- **æ¨èæ ‡ç­¾ï¼š**
  - æŠ€æœ¯ï¼š`RAG`, `LangChain`, `ChromaDB`, `Vector-Database`, `Semantic-Search`, `NLP`, `LLM`, `Embeddings`
  - åº”ç”¨ï¼š`Research-Assistant`, `Q&A-System`, `Knowledge-Base`, `Document-Search`, `Chatbot`
  - é¢†åŸŸï¼š`Machine-Learning`, `AI`, `Academic-Research`, `Literature-Review`
  - æ–¹æ³•ï¼š`Retrieval-Augmented-Generation`, `Similarity-Search`, `Text-Mining`
- **å·¥ä½œé‡ï¼š30åˆ†é’Ÿ**

#### 4. æ·»åŠ æ–‡æ¡£é¢†åŸŸå®šä¹‰
- [ ] åœ¨ README ä¸­æ·»åŠ  "Document Domain" ç« èŠ‚
- **å†…å®¹ï¼š**
```markdown
## ğŸ“š Document Domain

### Supported Document Types
- **Primary Focus**: Academic papers, research publications, technical documentation
- **Domain**: Machine Learning, Artificial Intelligence, Data Science
- **Format**: Text files (.txt) - expandable to PDF, DOCX
- **Content Characteristics**: Long-form technical content, structured information

### Best Suited For
âœ… Technical and academic research papers
âœ… Machine learning literature and publications
âœ… Technical documentation and whitepapers
âœ… Educational materials and course notes

### Not Recommended For
âŒ Creative writing or fiction
âŒ News articles or blog posts
âŒ Social media content
âŒ Unstructured conversational text
```
- **å·¥ä½œé‡ï¼š1å°æ—¶**

---

### Phase 2: é«˜ä¼˜å…ˆçº§ï¼ˆ3-5å¤©ï¼‰ğŸ“ P1
**ç›®æ ‡ï¼šå®Œå–„å†…å®¹å’Œæ–‡æ¡£**

#### 5. è¯¦ç»†å®‰è£…å’Œä½¿ç”¨è¯´æ˜
- [ ] æ·»åŠ ç³»ç»Ÿè¦æ±‚ç« èŠ‚
- [ ] é€æ­¥å®‰è£…æŒ‡å—ï¼ˆå¸¦æˆªå›¾ï¼‰
- [ ] é…ç½®è¯¦è§£ï¼ˆæ¯ä¸ªç¯å¢ƒå˜é‡çš„å«ä¹‰ï¼‰
- [ ] ä½¿ç”¨ç¤ºä¾‹ï¼ˆå¤šä¸ªåœºæ™¯ï¼‰
- [ ] æ•…éšœæ’æŸ¥ç« èŠ‚
- **å·¥ä½œé‡ï¼š1å¤©**

**æ–°å¢å†…å®¹ç»“æ„ï¼š**
```markdown
## ğŸ”§ System Requirements
- Python 3.8 or higher
- 4GB RAM minimum (8GB recommended)
- 2GB free disk space
- Internet connection (for API access)

## ğŸ“¦ Installation Guide

### Step 1: Clone the Repository
\`\`\`bash
git clone https://github.com/yourusername/project.git
cd project
\`\`\`

### Step 2: Create Virtual Environment
\`\`\`bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\\Scripts\\activate
\`\`\`

### Step 3: Install Dependencies
\`\`\`bash
pip install -r requirements.txt
\`\`\`

### Step 4: Configure Environment
\`\`\`bash
cp .env.example .env
# Edit .env and add your GROQ_API_KEY
\`\`\`

### Step 5: Verify Installation
\`\`\`bash
python start_chatbot.py
\`\`\`

## âš™ï¸ Configuration Parameters

| Parameter | Default | Description | Range |
|-----------|---------|-------------|-------|
| CHUNK_SIZE | 1000 | Characters per text chunk | 500-2000 |
| CHUNK_OVERLAP | 200 | Overlap between chunks | 50-500 |
| TOP_K_RESULTS | 5 | Number of retrieved chunks | 1-10 |
| LLM_MODEL_NAME | llama-3.1-8b-instant | Groq model name | See Groq docs |

## ğŸš¨ Troubleshooting

### Issue: "API key not valid"
**Solution**: Get your API key from https://console.groq.com/ and add to .env

### Issue: "No documents found"
**Solution**: Place .txt files in the documents/ folder

### Issue: "ChromaDB warnings"
**Solution**: Use start_chatbot.py instead of direct script execution
```

#### 6. å®é™…åº”ç”¨åœºæ™¯å’Œä»·å€¼
- [ ] æ·»åŠ  "Use Cases" ç« èŠ‚
- [ ] æ·»åŠ  "Real-world Applications" ç« èŠ‚
- [ ] æ·»åŠ  "Benefits and Impact" ç« èŠ‚
- **å·¥ä½œé‡ï¼š4å°æ—¶**

**å†…å®¹ç¤ºä¾‹ï¼š**
```markdown
## ğŸ’¼ Use Cases

### 1. Research Literature Review
**Scenario**: PhD student analyzing 50+ papers on deep learning
**Benefit**: Reduce literature review time from 2 weeks to 2 days (85% time saving)

### 2. Technical Documentation Assistant
**Scenario**: Software team managing internal ML documentation
**Benefit**: Instant access to past decisions and implementation details

### 3. Academic Course Support
**Scenario**: Professor providing 24/7 Q&A for course materials
**Benefit**: Improved student engagement and reduced office hours

### 4. Corporate Knowledge Management
**Scenario**: AI research lab maintaining institutional knowledge
**Benefit**: Preserve expertise and reduce knowledge loss from staff turnover

## ğŸ¯ Real-world Impact

- â±ï¸ **Time Savings**: Average 80% reduction in information retrieval time
- ğŸ“ˆ **Efficiency**: Handle 10x more document queries per day
- ğŸ“ **Accessibility**: Lower barrier to entry for complex research
- ğŸ’° **Cost**: Reduce manual research costs by ~$5000/month per researcher

## âœ¨ Key Benefits

1. **Speed**: Get answers in seconds vs. hours of manual search
2. **Accuracy**: Context-aware responses with source citations
3. **Scalability**: Process unlimited documents automatically
4. **Customizable**: Adapt to any research domain
```

#### 7. æŠ€æœ¯æ¶æ„å¯è§†åŒ–
- [ ] åˆ›å»ºç³»ç»Ÿæ¶æ„å›¾ï¼ˆä½¿ç”¨ Mermaid æˆ–å›¾ç‰‡ï¼‰
- [ ] åˆ›å»ºæ•°æ®æµå›¾
- [ ] æ·»åŠ åˆ° README
- **å·¥ä½œé‡ï¼š3å°æ—¶**

**æ¶æ„å›¾ç¤ºä¾‹ï¼ˆMermaidï¼‰ï¼š**
```markdown
## ğŸ—ï¸ Architecture

\`\`\`mermaid
graph TB
    A[User Query] --> B[Input Validation]
    B --> C[Guardrails Check]
    C --> D[Query Embedding]
    D --> E[Vector Search]
    F[Document Store] --> G[Text Chunking]
    G --> H[Embedding Generation]
    H --> I[ChromaDB]
    I --> E
    E --> J[Top-K Retrieval]
    J --> K[Context Building]
    K --> L[LLM Generation]
    L --> M[Response Validation]
    M --> N[User Response]
    N --> O[Memory Storage]
    O -.-> A
\`\`\`

### Data Flow

1. **Document Ingestion**: .txt files â†’ TextLoader â†’ RecursiveCharacterTextSplitter â†’ HuggingFace Embeddings â†’ ChromaDB
2. **Query Processing**: User input â†’ Validation â†’ Embedding â†’ Similarity Search â†’ Context Retrieval
3. **Response Generation**: Context + Prompt Template â†’ Groq LLM â†’ Guardrails â†’ User Output
```

#### 8. åŸºç¡€å®‰å…¨æ–‡æ¡£
- [ ] åˆ›å»º SECURITY.md
- [ ] è¯´æ˜ API å¯†é’¥ç®¡ç†
- [ ] è¯´æ˜æ•°æ®éšç§æªæ–½
- **å·¥ä½œé‡ï¼š2å°æ—¶**

---

### Phase 3: ä¸­ç­‰ä¼˜å…ˆçº§ï¼ˆ5-7å¤©ï¼‰ğŸ”§ P2
**ç›®æ ‡ï¼šå¢å¼ºæ ¸å¿ƒåŠŸèƒ½**

#### 9. å®ç° Guardrails ç³»ç»Ÿ
- [ ] åˆ›å»º `src/guardrails.py`
- [ ] è¾“å…¥éªŒè¯ï¼ˆé•¿åº¦ã€å†…å®¹ã€æ³¨å…¥æ£€æµ‹ï¼‰
- [ ] è¾“å‡ºæ§åˆ¶ï¼ˆç›¸å…³æ€§ã€ç½®ä¿¡åº¦ï¼‰
- [ ] é›†æˆåˆ°ä¸»ç¨‹åº
- **å·¥ä½œé‡ï¼š2å¤©**

**æŠ€æœ¯æ–¹æ¡ˆï¼š**
```python
# src/guardrails.py

class QueryGuardrails:
    """è¾“å…¥éªŒè¯å’Œé˜²æŠ¤"""

    def __init__(self):
        self.min_length = 3
        self.max_length = 500
        self.blocked_patterns = [...]  # SQLæ³¨å…¥ç­‰

    def validate_query(self, query: str) -> tuple[bool, str]:
        """éªŒè¯æŸ¥è¯¢è¾“å…¥"""
        # é•¿åº¦æ£€æŸ¥
        if len(query) < self.min_length:
            return False, "Query too short (min 3 characters)"

        if len(query) > self.max_length:
            return False, f"Query too long (max {self.max_length} characters)"

        # æ¶æ„æ¨¡å¼æ£€æµ‹
        if self._contains_injection(query):
            return False, "Invalid input pattern detected"

        # é¢†åŸŸç›¸å…³æ€§æ£€æŸ¥ï¼ˆå¯é€‰ï¼‰
        if not self._is_research_related(query):
            return False, "Query appears outside research domain"

        return True, "Valid query"

    def _contains_injection(self, query: str) -> bool:
        """æ£€æµ‹æ³¨å…¥æ”»å‡»æ¨¡å¼"""
        # å®ç°SQLæ³¨å…¥ã€å‘½ä»¤æ³¨å…¥æ£€æµ‹
        pass

    def _is_research_related(self, query: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ç ”ç©¶ç›¸å…³"""
        # ä½¿ç”¨å…³é”®è¯æˆ–åˆ†ç±»å™¨
        pass

class ResponseGuardrails:
    """è¾“å‡ºéªŒè¯å’Œè´¨é‡æ§åˆ¶"""

    def __init__(self, confidence_threshold=0.5):
        self.confidence_threshold = confidence_threshold

    def validate_response(self, response: str, sources: list) -> tuple[bool, str]:
        """éªŒè¯å“åº”è´¨é‡"""
        # æ£€æŸ¥æ˜¯å¦åŸºäºæ£€ç´¢å†…å®¹
        if not self._has_source_overlap(response, sources):
            return False, "Response not grounded in sources"

        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = self._calculate_confidence(response, sources)
        if confidence < self.confidence_threshold:
            return False, f"Low confidence: {confidence:.2f}"

        # é•¿åº¦æ£€æŸ¥
        if len(response) < 50:
            return False, "Response too short"

        return True, "Valid response"

    def _has_source_overlap(self, response: str, sources: list) -> bool:
        """æ£€æŸ¥å“åº”æ˜¯å¦åŸºäºæ¥æº"""
        # å®ç°æ–‡æœ¬é‡å åº¦æ£€æŸ¥
        pass

    def _calculate_confidence(self, response: str, sources: list) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦åˆ†æ•°"""
        # åŸºäºæ£€ç´¢åˆ†æ•°ã€æ–‡æœ¬é‡å åº¦ç­‰
        pass

class RateLimiter:
    """è®¿é—®é¢‘ç‡é™åˆ¶"""

    def __init__(self, max_requests_per_minute=10):
        self.max_requests = max_requests_per_minute
        self.requests = {}

    def check_rate_limit(self, user_id: str) -> tuple[bool, str]:
        """æ£€æŸ¥æ˜¯å¦è¶…è¿‡é¢‘ç‡é™åˆ¶"""
        # å®ç°ä»¤ç‰Œæ¡¶æˆ–æ»‘åŠ¨çª—å£ç®—æ³•
        pass
```

**é›†æˆåˆ°ä¸»ç¨‹åºï¼š**
```python
# åœ¨ rt_lc_chatbot.py ä¸­
from src.guardrails import QueryGuardrails, ResponseGuardrails

query_guards = QueryGuardrails()
response_guards = ResponseGuardrails()

def safe_answer_research_question(query, collection, embeddings, llm):
    """å¸¦å®‰å…¨é˜²æŠ¤çš„é—®ç­”"""
    # è¾“å…¥éªŒè¯
    is_valid, message = query_guards.validate_query(query)
    if not is_valid:
        return f"âŒ Invalid query: {message}", []

    # åŸæœ‰æŸ¥è¯¢é€»è¾‘
    answer, sources = answer_research_question(query, collection, embeddings, llm)

    # è¾“å‡ºéªŒè¯
    is_valid, message = response_guards.validate_response(answer, sources)
    if not is_valid:
        return f"âš ï¸ Response validation failed: {message}", sources

    return answer, sources
```

#### 10. å®ç°è®°å¿†æœºåˆ¶
- [ ] åˆ›å»º `src/memory_manager.py`
- [ ] é›†æˆ LangChain ConversationBufferMemory
- [ ] å¯¹è¯å†å²ç®¡ç†
- [ ] æµ‹è¯•å¤šè½®å¯¹è¯
- **å·¥ä½œé‡ï¼š1.5å¤©**

**æŠ€æœ¯æ–¹æ¡ˆï¼š**
```python
# src/memory_manager.py

from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain

class ConversationManager:
    """ç®¡ç†å¯¹è¯å†å²å’Œä¸Šä¸‹æ–‡"""

    def __init__(self, llm, vectorstore, max_history=5):
        """
        Args:
            llm: è¯­è¨€æ¨¡å‹
            vectorstore: å‘é‡æ•°æ®åº“
            max_history: ä¿ç•™çš„å¯¹è¯è½®æ•°
        """
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            output_key="answer",
            max_token_limit=2000  # é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
        )

        self.qa_chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=vectorstore.as_retriever(search_kwargs={"k": 5}),
            memory=self.memory,
            return_source_documents=True,
            verbose=False
        )

    def chat(self, query: str) -> dict:
        """
        è¿›è¡Œå¯¹è¯ï¼Œè‡ªåŠ¨ç»´æŠ¤å†å²

        Returns:
            {
                "answer": str,
                "source_documents": list,
                "chat_history": list
            }
        """
        result = self.qa_chain({"question": query})
        return result

    def get_history(self) -> list:
        """è·å–å¯¹è¯å†å²"""
        return self.memory.chat_memory.messages

    def clear_history(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.memory.clear()

    def save_session(self, filepath: str):
        """ä¿å­˜ä¼šè¯åˆ°æ–‡ä»¶"""
        import json
        history = [
            {"role": msg.type, "content": msg.content}
            for msg in self.memory.chat_memory.messages
        ]
        with open(filepath, 'w') as f:
            json.dump(history, f, indent=2)

    def load_session(self, filepath: str):
        """ä»æ–‡ä»¶åŠ è½½ä¼šè¯"""
        import json
        with open(filepath, 'r') as f:
            history = json.load(f)
        # é‡å»ºè®°å¿†
        # ...

# åœ¨ä¸»ç¨‹åºä¸­ä½¿ç”¨
def main_with_memory():
    """å¸¦è®°å¿†çš„ä¸»å‡½æ•°"""
    llm = ChatGroq(...)

    # åˆ›å»ºå‘é‡å­˜å‚¨æ£€ç´¢å™¨
    from langchain.vectorstores import Chroma
    vectorstore = Chroma(
        client=client,
        collection_name="ml_publications",
        embedding_function=embeddings
    )

    # åˆ›å»ºå¯¹è¯ç®¡ç†å™¨
    conversation_manager = ConversationManager(llm, vectorstore)

    print("\n=== Research Assistant with Memory ===")
    print("Now with conversation history! Type 'clear' to reset, 'quit' to exit.\n")

    while True:
        query = input("Your question: ").strip()

        if query.lower() in ['quit', 'exit', 'q']:
            print("ğŸ‘‹ Goodbye!")
            break

        if query.lower() == 'clear':
            conversation_manager.clear_history()
            print("âœ… Conversation history cleared.")
            continue

        if not query:
            continue

        try:
            result = conversation_manager.chat(query)

            print(f"\nğŸ¤– Answer: {result['answer']}")
            print("\nğŸ“š Sources:")
            for i, doc in enumerate(result['source_documents'], 1):
                print(f"  {i}. {doc.metadata.get('title', 'N/A')}")
            print("-" * 80)

        except Exception as e:
            print(f"âŒ Error: {str(e)}")
            print("-" * 80)
```

#### 11. åŸºç¡€è¯„ä¼°ç³»ç»Ÿ
- [ ] åˆ›å»º `src/evaluation.py`
- [ ] å®ç° Precision@K, Recall@K
- [ ] æ€§èƒ½ç›‘æ§ï¼ˆå»¶è¿Ÿè¿½è¸ªï¼‰
- [ ] ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
- **å·¥ä½œé‡ï¼š2å¤©**

**æŠ€æœ¯æ–¹æ¡ˆï¼š**
```python
# src/evaluation.py

import time
import numpy as np
from typing import List, Dict
import pandas as pd

class RetrievalEvaluator:
    """æ£€ç´¢è´¨é‡è¯„ä¼°"""

    def __init__(self, collection, embeddings):
        self.collection = collection
        self.embeddings = embeddings

    def precision_at_k(self, query: str, relevant_docs: List[str], k: int = 5) -> float:
        """
        è®¡ç®— Precision@K

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            relevant_docs: ç›¸å…³æ–‡æ¡£IDåˆ—è¡¨ï¼ˆground truthï¼‰
            k: è¿”å›å‰Kä¸ªç»“æœ
        """
        # æ‰§è¡Œæ£€ç´¢
        results = search_research_db(query, self.collection, self.embeddings, top_k=k)

        # è®¡ç®—ç²¾ç¡®ç‡
        retrieved_ids = [r.get('chunk_id') for r in results]
        relevant_retrieved = len(set(retrieved_ids) & set(relevant_docs))

        return relevant_retrieved / k if k > 0 else 0.0

    def recall_at_k(self, query: str, relevant_docs: List[str], k: int = 5) -> float:
        """è®¡ç®— Recall@K"""
        results = search_research_db(query, self.collection, self.embeddings, top_k=k)

        retrieved_ids = [r.get('chunk_id') for r in results]
        relevant_retrieved = len(set(retrieved_ids) & set(relevant_docs))

        total_relevant = len(relevant_docs)
        return relevant_retrieved / total_relevant if total_relevant > 0 else 0.0

    def mean_reciprocal_rank(self, queries: List[str], ground_truth: List[List[str]]) -> float:
        """
        è®¡ç®— MRR (Mean Reciprocal Rank)

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨
            ground_truth: æ¯ä¸ªæŸ¥è¯¢çš„ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        reciprocal_ranks = []

        for query, relevant_docs in zip(queries, ground_truth):
            results = search_research_db(query, self.collection, self.embeddings, top_k=10)
            retrieved_ids = [r.get('chunk_id') for r in results]

            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªç›¸å…³æ–‡æ¡£çš„ä½ç½®
            for rank, doc_id in enumerate(retrieved_ids, 1):
                if doc_id in relevant_docs:
                    reciprocal_ranks.append(1.0 / rank)
                    break
            else:
                reciprocal_ranks.append(0.0)

        return np.mean(reciprocal_ranks) if reciprocal_ranks else 0.0

    def evaluate_batch(self, test_queries: List[Dict]) -> Dict:
        """
        æ‰¹é‡è¯„ä¼°

        Args:
            test_queries: [{"query": str, "relevant_docs": List[str]}, ...]

        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        precision_scores = []
        recall_scores = []

        for item in test_queries:
            query = item['query']
            relevant = item['relevant_docs']

            p = self.precision_at_k(query, relevant, k=5)
            r = self.recall_at_k(query, relevant, k=5)

            precision_scores.append(p)
            recall_scores.append(r)

        return {
            'avg_precision@5': np.mean(precision_scores),
            'avg_recall@5': np.mean(recall_scores),
            'num_queries': len(test_queries)
        }

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§"""

    def __init__(self):
        self.metrics = []

    def measure_latency(self, func):
        """å»¶è¿Ÿæµ‹é‡è£…é¥°å™¨"""
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            latency = time.time() - start_time

            self.metrics.append({
                'function': func.__name__,
                'latency': latency,
                'timestamp': time.time()
            })

            return result
        return wrapper

    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if not self.metrics:
            return {}

        df = pd.DataFrame(self.metrics)

        stats = {}
        for func_name in df['function'].unique():
            func_metrics = df[df['function'] == func_name]['latency']
            stats[func_name] = {
                'mean': func_metrics.mean(),
                'median': func_metrics.median(),
                'p95': func_metrics.quantile(0.95),
                'p99': func_metrics.quantile(0.99),
                'count': len(func_metrics)
            }

        return stats

    def generate_report(self, filepath: str = 'performance_report.txt'):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        stats = self.get_stats()

        with open(filepath, 'w') as f:
            f.write("=== Performance Report ===\n\n")

            for func_name, metrics in stats.items():
                f.write(f"\n{func_name}:\n")
                f.write(f"  Mean latency: {metrics['mean']:.3f}s\n")
                f.write(f"  Median: {metrics['median']:.3f}s\n")
                f.write(f"  P95: {metrics['p95']:.3f}s\n")
                f.write(f"  P99: {metrics['p99']:.3f}s\n")
                f.write(f"  Total calls: {metrics['count']}\n")

        print(f"âœ… Performance report saved to {filepath}")

# ä½¿ç”¨ç¤ºä¾‹
monitor = PerformanceMonitor()

@monitor.measure_latency
def answer_research_question_monitored(query, collection, embeddings, llm):
    """å¸¦æ€§èƒ½ç›‘æ§çš„é—®ç­”"""
    return answer_research_question(query, collection, embeddings, llm)
```

#### 12. çŸ¥è¯†åº“ç®¡ç†å·¥å…·
- [ ] åˆ›å»º `src/kb_manager.py`
- [ ] æ–‡æ¡£ç®¡ç†åŠŸèƒ½ï¼ˆå¢åˆ æ”¹æŸ¥ï¼‰
- [ ] ç»Ÿè®¡å’ŒæŠ¥å‘Š
- [ ] CLI å·¥å…·
- **å·¥ä½œé‡ï¼š1.5å¤©**

**æŠ€æœ¯æ–¹æ¡ˆï¼š**
```python
# src/kb_manager.py

import os
import json
from datetime import datetime

class KnowledgeBaseManager:
    """çŸ¥è¯†åº“ç®¡ç†å·¥å…·"""

    def __init__(self, collection, embeddings, documents_path="./documents"):
        self.collection = collection
        self.embeddings = embeddings
        self.documents_path = documents_path

    def get_statistics(self) -> Dict:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        count = self.collection.count()

        # è·å–æ‰€æœ‰æ–‡æ¡£çš„å…ƒæ•°æ®
        results = self.collection.get()
        metadatas = results.get('metadatas', [])

        # ç»Ÿè®¡æ–‡æ¡£æ¥æº
        sources = {}
        for meta in metadatas:
            source = meta.get('source', 'unknown')
            sources[source] = sources.get(source, 0) + 1

        return {
            'total_chunks': count,
            'total_documents': len(sources),
            'sources': sources,
            'last_updated': datetime.now().isoformat()
        }

    def add_document(self, file_path: str, metadata: Dict = None):
        """æ·»åŠ å•ä¸ªæ–‡æ¡£"""
        # åŠ è½½æ–‡æ¡£
        from langchain_community.document_loaders import TextLoader
        loader = TextLoader(file_path)
        doc = loader.load()[0]

        # åˆ†å—
        chunks = chunk_publication(doc.page_content)

        # ç”ŸæˆåµŒå…¥
        embeddings_list = embed_documents(chunks)

        # å‡†å¤‡å…ƒæ•°æ®
        base_meta = metadata or {}
        base_meta['source'] = os.path.basename(file_path)
        base_meta['added_at'] = datetime.now().isoformat()

        # æ’å…¥æ•°æ®åº“
        ids = [f"{base_meta['source']}_chunk_{i}" for i in range(len(chunks))]
        metadatas = [{**base_meta, 'chunk_id': id} for id in ids]

        self.collection.add(
            embeddings=embeddings_list,
            documents=chunks,
            ids=ids,
            metadatas=metadatas
        )

        print(f"âœ… Added {len(chunks)} chunks from {file_path}")

    def remove_document(self, source_name: str):
        """åˆ é™¤æ–‡æ¡£ï¼ˆæŒ‰æ¥æºï¼‰"""
        # æŸ¥è¯¢è¯¥æ¥æºçš„æ‰€æœ‰æ–‡æ¡£
        results = self.collection.get(
            where={"source": source_name}
        )

        if not results['ids']:
            print(f"âš ï¸ No documents found with source: {source_name}")
            return

        # åˆ é™¤
        self.collection.delete(ids=results['ids'])
        print(f"âœ… Removed {len(results['ids'])} chunks from {source_name}")

    def update_document(self, file_path: str):
        """æ›´æ–°æ–‡æ¡£ï¼ˆå…ˆåˆ é™¤å†æ·»åŠ ï¼‰"""
        source_name = os.path.basename(file_path)
        self.remove_document(source_name)
        self.add_document(file_path)

    def rebuild_index(self):
        """é‡å»ºæ•´ä¸ªç´¢å¼•"""
        print("ğŸ”„ Rebuilding knowledge base...")

        # æ¸…ç©ºå½“å‰collection
        self.collection.delete(where={})

        # é‡æ–°åŠ è½½æ‰€æœ‰æ–‡æ¡£
        publications = load_research_publications(self.documents_path)
        insert_publications(self.collection, publications)

        print("âœ… Knowledge base rebuilt successfully")

    def export_metadata(self, filepath: str = 'kb_metadata.json'):
        """å¯¼å‡ºå…ƒæ•°æ®"""
        stats = self.get_statistics()

        with open(filepath, 'w') as f:
            json.dump(stats, f, indent=2)

        print(f"âœ… Metadata exported to {filepath}")

    def search_by_source(self, source_name: str) -> List[Dict]:
        """æŒ‰æ¥æºæœç´¢æ–‡æ¡£"""
        results = self.collection.get(
            where={"source": source_name}
        )

        return [
            {
                'id': results['ids'][i],
                'content': results['documents'][i][:200] + '...',  # é¢„è§ˆ
                'metadata': results['metadatas'][i]
            }
            for i in range(len(results['ids']))
        ]

# CLI å·¥å…·
def kb_cli():
    """å‘½ä»¤è¡Œå·¥å…·"""
    import argparse

    parser = argparse.ArgumentParser(description='Knowledge Base Management')
    parser.add_argument('command', choices=['stats', 'add', 'remove', 'rebuild', 'export'])
    parser.add_argument('--file', help='File path for add/remove')
    parser.add_argument('--source', help='Source name for remove')

    args = parser.parse_args()

    # åˆå§‹åŒ–
    # ... (åŠ è½½collection, embeddings)

    manager = KnowledgeBaseManager(collection, embeddings)

    if args.command == 'stats':
        stats = manager.get_statistics()
        print(json.dumps(stats, indent=2))

    elif args.command == 'add':
        if not args.file:
            print("âŒ --file required")
            return
        manager.add_document(args.file)

    elif args.command == 'remove':
        if not args.source:
            print("âŒ --source required")
            return
        manager.remove_document(args.source)

    elif args.command == 'rebuild':
        manager.rebuild_index()

    elif args.command == 'export':
        manager.export_metadata()

if __name__ == '__main__':
    kb_cli()
```

---

### Phase 4: ä½ä¼˜å…ˆçº§ï¼ˆ7-10å¤©ï¼‰ğŸ“Š P3
**ç›®æ ‡ï¼šå®Œå–„å’Œæå‡**

#### 13. é«˜çº§è¯„ä¼°å’ŒåŸºå‡†æµ‹è¯•
- [ ] å®ç° NDCG (Normalized Discounted Cumulative Gain)
- [ ] åˆ›å»ºæ ‡å‡†æµ‹è¯•æ•°æ®é›†
- [ ] åŸºå‡†æµ‹è¯•æŠ¥å‘Š
- [ ] ä¸baselineå¯¹æ¯”
- **å·¥ä½œé‡ï¼š3å¤©**

#### 14. å®Œæ•´æ–‡æ¡£å¥—ä»¶
- [ ] åˆ›å»º ARCHITECTURE.md - è¯¦ç»†æŠ€æœ¯æ¶æ„
- [ ] åˆ›å»º EVALUATION.md - æ€§èƒ½è¯„ä¼°æŠ¥å‘Š
- [ ] åˆ›å»º CONTRIBUTING.md - è´¡çŒ®æŒ‡å—
- [ ] åˆ›å»º API.md - APIæ–‡æ¡£ï¼ˆå¦‚æœéœ€è¦ï¼‰
- [ ] åˆ›å»º CHANGELOG.md - ç‰ˆæœ¬å†å²
- **å·¥ä½œé‡ï¼š3å¤©**

#### 15. ç¤ºä¾‹å’Œæ•™ç¨‹
- [ ] åˆ›å»º `examples/` ç›®å½•
  - `basic_usage.py` - åŸºæœ¬ç”¨æ³•
  - `advanced_queries.py` - é«˜çº§æŸ¥è¯¢
  - `evaluation_demo.py` - è¯„ä¼°æ¼”ç¤º
  - `batch_processing.py` - æ‰¹é‡å¤„ç†
- [ ] åˆ›å»º Jupyter notebooks
  - `Tutorial.ipynb` - äº¤äº’å¼æ•™ç¨‹
  - `Evaluation_Analysis.ipynb` - è¯„ä¼°åˆ†æ
- **å·¥ä½œé‡ï¼š3å¤©**

#### 16. è§†è§‰å…ƒç´ å’Œæˆªå›¾
- [ ] åˆ›å»ºç³»ç»Ÿæ¶æ„å›¾ï¼ˆä¸“ä¸šè®¾è®¡ï¼‰
- [ ] Hero å›¾ç‰‡ï¼ˆ1200x630pxï¼‰
- [ ] ç•Œé¢æˆªå›¾ï¼ˆ3-5å¼ ï¼‰
- [ ] æ€§èƒ½å›¾è¡¨å’Œå¯è§†åŒ–
- **å·¥ä½œé‡ï¼š1å¤©**

---

## ğŸ“‹ å®Œæ•´ Checklist

### Publication åˆè§„
- [ ] âœ… é¡¹ç›®æ ‡é¢˜å…·ä½“ä¸”æœ‰æ„ä¹‰
- [ ] âœ… åŒ…å« LICENSE æ–‡ä»¶
- [ ] âœ… è‡³å°‘ 10 ä¸ªç›¸å…³æ ‡ç­¾
- [ ] âœ… Hero å›¾ç‰‡ä¸“ä¸šä¸”ç›¸å…³
- [ ] âœ… README ç»“æ„å®Œæ•´
- [ ] âœ… è¯¦ç»†å®‰è£…è¯´æ˜
- [ ] âœ… ä½¿ç”¨ç¤ºä¾‹å’Œæˆªå›¾
- [ ] âœ… å®é™…åº”ç”¨åœºæ™¯ï¼ˆ3+ä¸ªï¼‰
- [ ] âœ… æŠ€æœ¯æ¶æ„å›¾
- [ ] âœ… é…ç½®å‚æ•°æ–‡æ¡£
- [ ] âœ… æ•…éšœæ’æŸ¥ç« èŠ‚

### æŠ€æœ¯åŠŸèƒ½
- [ ] âœ… Guardrails ç³»ç»Ÿ
- [ ] âœ… SECURITY.md
- [ ] âœ… è®°å¿†æœºåˆ¶
- [ ] âœ… æ£€ç´¢è¯„ä¼°ï¼ˆPrecision@K, Recall@Kï¼‰
- [ ] âœ… æ€§èƒ½ç›‘æ§
- [ ] âœ… æ–‡æ¡£é¢†åŸŸå®šä¹‰
- [ ] âœ… çŸ¥è¯†åº“ç®¡ç†å·¥å…·

### æ–‡æ¡£å®Œæ•´æ€§
- [ ] âœ… README.mdï¼ˆé‡æ„ï¼‰
- [ ] âœ… LICENSE
- [ ] âœ… SECURITY.md
- [ ] âœ… ARCHITECTURE.md
- [ ] âœ… EVALUATION.md
- [ ] âœ… CONTRIBUTING.md
- [ ] âœ… CHANGELOG.md

### è§†è§‰å…ƒç´ 
- [ ] âœ… Hero å›¾ç‰‡
- [ ] âœ… ç³»ç»Ÿæ¶æ„å›¾
- [ ] âœ… æ•°æ®æµå›¾
- [ ] âœ… ä½¿ç”¨ç¤ºä¾‹æˆªå›¾
- [ ] âœ… æ€§èƒ½å›¾è¡¨
- [ ] âœ… README å¾½ç« 

---

## ğŸ¯ å…³é”®æˆåŠŸå› ç´ 

### 1. æ¸…æ™°åº¦ (Clarity)
- ä½¿ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€
- é€»è¾‘ç»“æ„æ¸…æ™°
- ä»£ç æ³¨é‡Šå®Œæ•´
- ç¤ºä¾‹æ˜“äºç†è§£

### 2. å®Œæ•´æ€§ (Completeness)
- è¦†ç›–æ‰€æœ‰åé¦ˆç‚¹
- æ–‡æ¡£é½å…¨è¯¦å°½
- åŠŸèƒ½å®Œæ•´å¯ç”¨
- æµ‹è¯•å……åˆ†æœ‰æ•ˆ

### 3. ç›¸å…³æ€§ (Relevance)
- å¯¹æ ‡è¡Œä¸šè¶‹åŠ¿ï¼ˆRAGã€LLMï¼‰
- å®é™…åº”ç”¨åœºæ™¯çœŸå®
- è§£å†³å®é™…é—®é¢˜
- æŠ€æœ¯é€‰å‹åˆç†

### 4. å‚ä¸åº¦ (Engagement)
- è§†è§‰å…ƒç´ ä¸°å¯Œ
- äº¤äº’ç¤ºä¾‹å……è¶³
- æ˜“äºä¸Šæ‰‹ä½¿ç”¨
- ç¤¾åŒºå‹å¥½å¼€æ”¾

---

## âš ï¸ é£é™©å’ŒæŒ‘æˆ˜

### æ½œåœ¨é£é™©

1. **æ—¶é—´æŠ•å…¥å¤§**
   - **ç¼“è§£æªæ–½**ï¼šåˆ†é˜¶æ®µå®æ–½ï¼Œä¼˜å…ˆ P0 å’Œ P1

2. **æŠ€æœ¯å¤æ‚åº¦**
   - **ç¼“è§£æªæ–½**ï¼šä½¿ç”¨æˆç†Ÿåº“ï¼ˆLangChainï¼‰ï¼Œå‚è€ƒç°æœ‰å®ç°

3. **è¯„ä¼°æ•°æ®ç¼ºå¤±**
   - **ç¼“è§£æªæ–½**ï¼šåˆ›å»ºåˆæˆæµ‹è¯•é›†ï¼Œä½¿ç”¨å…¬å¼€æ•°æ®é›†

4. **æ€§èƒ½å¼€é”€**
   - **ç¼“è§£æªæ–½**ï¼šå¯é…ç½®å¼€å…³ï¼Œå¼‚æ­¥å¤„ç†ï¼Œç¼“å­˜ä¼˜åŒ–

---

## ğŸ“¦ ä¾èµ–æ›´æ–°

éœ€è¦åœ¨ `requirements.txt` ä¸­æ·»åŠ ï¼š

```txt
# ç°æœ‰ä¾èµ–...

# è¯„ä¼°å’Œç›‘æ§
numpy>=1.24.0
pandas>=2.0.0
scikit-learn>=1.3.0

# éªŒè¯
pydantic>=2.0.0

# å¯é€‰ï¼šæ—¥å¿—
loguru>=0.7.0

# å¯é€‰ï¼šé«˜çº§è¯„ä¼°
nltk>=3.8
rouge-score>=0.1.0
```

---

## ğŸ“Š é¢„æœŸæ—¶é—´çº¿

- **Phase 1 (P0)**: 1-2 å¤© âœ… åŸºç¡€åˆè§„
- **Phase 2 (P1)**: 3-5 å¤© âœ… å†…å®¹å®Œå–„
- **Phase 3 (P2)**: 5-7 å¤© âœ… åŠŸèƒ½å¢å¼º
- **Phase 4 (P3)**: 7-10 å¤© âœ… å®Œå–„æå‡

**æ€»è®¡**: 3-4 å‘¨å®Œæˆæ‰€æœ‰æ”¹è¿›

**å¿«é€Ÿè·¯å¾„**: ä¸“æ³¨ Phase 1-2ï¼Œå¯åœ¨ 1 å‘¨å†…æ»¡è¶³åŸºæœ¬è¦æ±‚

---

## ğŸš€ ç«‹å³è¡ŒåŠ¨é¡¹ï¼ˆæœ¬å‘¨å†…ï¼‰

1. âœ… æ·»åŠ  LICENSE æ–‡ä»¶ï¼ˆMITï¼‰
2. âœ… æ›´æ–°é¡¹ç›®æ ‡é¢˜ä¸ºå…·ä½“åç§°
3. âœ… æ·»åŠ  10+ é¡¹ç›®æ ‡ç­¾
4. âœ… æ·»åŠ æ–‡æ¡£é¢†åŸŸå®šä¹‰ç« èŠ‚
5. âœ… åˆ›å»ºåŸºç¡€ SECURITY.md
6. âœ… æ·»åŠ  README å¾½ç« 

---

## ğŸ“š å‚è€ƒèµ„æº

- ReadyTensor æœ€ä½³å®è·µ: https://app.readytensor.ai/publications/checklist-for-a-high-quality-ready-tensor-publication-JNgtglsVpvrj
- å‘å¸ƒæŒ‡å—: https://app.readytensor.ai/publications/engage-and-inspire-best-practices-for-publishing-on-ready-tensor-SBgkOyUsP8qQ
- LangChain Memory: https://python.langchain.com/docs/modules/memory/
- RAG æœ€ä½³å®è·µ: https://www.anthropic.com/research/building-effective-agents

---

## âœ… éªŒæ”¶æ ‡å‡†

é¡¹ç›®å°†åœ¨ä»¥ä¸‹æ¡ä»¶ä¸‹è¢«è®¤ä¸ºå®Œæˆï¼š

1. âœ… æ‰€æœ‰ P0 å’Œ P1 ä»»åŠ¡å®Œæˆ
2. âœ… README åŒ…å«æ‰€æœ‰å¿…éœ€ç« èŠ‚
3. âœ… è‡³å°‘ 3 ä¸ªæ ¸å¿ƒåŠŸèƒ½æœ‰æµ‹è¯•
4. âœ… æ–‡æ¡£å®¡é˜…é€šè¿‡
5. âœ… ReadyTensor è‡ªåŠ¨è¯„ä¼°åˆ†æ•°æå‡
6. âœ… æ‰€æœ‰åé¦ˆç‚¹éƒ½æœ‰å¯¹åº”çš„æ”¹è¿›

---

**æœ€åæ›´æ–°**: 2025-10-11
**ç‰ˆæœ¬**: 1.0
**ä½œè€…**: Claude Code Analysis
